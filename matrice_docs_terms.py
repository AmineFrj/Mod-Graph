# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nABCOJ5bUabeR8kv0stBMNX5-tc9ThA-
"""

! pip install pandas as pd

import pandas as pd
data_auteurs=pd.read_csv('Liste_Auteurs_affiliationÃ¨_photo.csv',sep='\t')
data_articles=pd.read_csv('export_articles_EGC_2004_2018 (2).csv',sep='\t')

data_articles.head()
data_articles.columns

len(data_articles)

data_articles=data_articles[data_articles['abstract'].notna()]

len(data_articles)

data_articles['title']=data_articles['title'].apply(lambda x: ' '.join(x.lower() for x in x.split() ) )
data_articles['title']

import string
data_articles['title']=data_articles['title'].apply(lambda x: ' '.join(x for x in x.split() if not x.isdigit() ))
data_articles['title']=data_articles['title'].str.replace('[^\w\s]'," ")
data_articles['title']

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize
nltk.download('stopwords')

english_stopwords=set(stopwords.words('english'))
french_stopwords = set(stopwords.words('french'))

data_articles['title']=data_articles['title'].apply(lambda x: ' '.join(x for x in x.split() if x not in french_stopwords ))
data_articles['title']=data_articles['title'].apply(lambda x: ' '.join(x for x in x.split() if x not in english_stopwords ))

from sklearn.feature_extraction.text import CountVectorizer
from nltk.tokenize import RegexpTokenizer
#tokenizer to remove unwanted elements from out data like symbols and numbers

cv = CountVectorizer()
text_counts= cv.fit_transform(data_articles['title'])

M=text_counts.toarray()

M[M>1]=1

import numpy as np
np.savetxt('Doc_Term_Matrix.csv',M,delimiter=";")

A=pd.read_csv("docAut-1.csv",sep="\t")

AT=A.T

E=AT.dot(M)

np.sum(np.sum(E)==0)

E.dot(E.T)